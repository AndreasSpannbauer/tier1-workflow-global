# Tier 1 Workflow - Comprehensive Technical Guide

**Complete technical reference for the Tier 1 workflow system**

**Date:** 2025-10-19
**Version:** 1.0
**Status:** Production Ready (Week 4 Complete - 67% of roadmap)

---

## Table of Contents

1. [Architecture Overview](#architecture-overview)
2. [Orchestrator Pattern](#orchestrator-pattern)
3. [Agent System](#agent-system)
4. [Phase-by-Phase Deep Dive](#phase-by-phase-deep-dive)
5. [Parallel Execution System](#parallel-execution-system)
6. [Validation System](#validation-system)
7. [Post-Mortem System](#post-mortem-system)
8. [GitHub Integration](#github-integration)
9. [File Structure](#file-structure)
10. [Extension Points](#extension-points)
11. [Performance Characteristics](#performance-characteristics)
12. [Limitations and Trade-offs](#limitations-and-trade-offs)

---

## Architecture Overview

### System Purpose

The Tier 1 workflow automates software development from epic specification to commit, using AI agents orchestrated through Claude Code's Task tool.

**Key Design Principles:**
- **Orchestrator pattern:** Orchestrator coordinates, agents execute
- **Prescriptive plans:** Detailed file-level instructions (not high-level specs)
- **Agent composition:** Agents = definition + briefings + context
- **Parallel execution:** Automatic detection and worktree isolation
- **Non-blocking validation:** Workflow continues on validation failure
- **Knowledge capture:** Post-mortem analysis for continuous improvement

### High-Level Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User Creates Epic Spec (/spec-epic)                            â”‚
â”‚ â†’ spec.md (problem, requirements, acceptance criteria)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User Generates Implementation Plan (/refine-epic)              â”‚
â”‚ â†’ architecture.md (design decisions)                           â”‚
â”‚ â†’ file-tasks.md (prescriptive implementation plan)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User Executes Workflow (/execute-workflow EPIC-ID)             â”‚
â”‚                                                                 â”‚
â”‚  Phase 0: Preflight                                            â”‚
â”‚    â”œâ”€â–º Verify epic files exist                                â”‚
â”‚    â”œâ”€â–º Check git working directory clean                      â”‚
â”‚    â”œâ”€â–º Parallel detection (file count, domains, overlap)      â”‚
â”‚    â””â”€â–º Set execution mode (sequential or parallel)            â”‚
â”‚                                                                 â”‚
â”‚  Phase 1: Implementation                                       â”‚
â”‚    â”œâ”€â–º Sequential (1A):                                       â”‚
â”‚    â”‚     â””â”€â–º Deploy single implementation agent              â”‚
â”‚    â”‚                                                           â”‚
â”‚    â””â”€â–º Parallel (1B + 1C):                                   â”‚
â”‚          â”œâ”€â–º Create worktrees per domain                     â”‚
â”‚          â”œâ”€â–º Deploy parallel agents (single message)         â”‚
â”‚          â”œâ”€â–º Wait for completion                             â”‚
â”‚          â””â”€â–º Sequential merge (dependency order)             â”‚
â”‚                                                                 â”‚
â”‚  Phase 3: Validation (with retry loop)                        â”‚
â”‚    â”œâ”€â–º Run validation (npm run validate-all)                 â”‚
â”‚    â”œâ”€â–º If fails: Deploy build fixer agent                    â”‚
â”‚    â”œâ”€â–º Retry validation (max 3 attempts)                     â”‚
â”‚    â””â”€â–º Continue workflow (non-blocking)                      â”‚
â”‚                                                                 â”‚
â”‚  Phase 5: Commit & Cleanup                                    â”‚
â”‚    â”œâ”€â–º Create conventional commit                            â”‚
â”‚    â”œâ”€â–º Move epic to completed/                               â”‚
â”‚    â””â”€â–º Close GitHub issues (optional)                        â”‚
â”‚                                                                 â”‚
â”‚  Phase 6: Post-Mortem                                         â”‚
â”‚    â”œâ”€â–º Deploy post-mortem agent                              â”‚
â”‚    â”œâ”€â–º Analyze workflow artifacts                            â”‚
â”‚    â”œâ”€â–º Generate recommendations                              â”‚
â”‚    â””â”€â–º Write structured markdown report                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Outputs:                                                        â”‚
â”‚  - Commit created (feat(EPIC-ID): ...)                        â”‚
â”‚  - Epic moved to .tasks/completed/                            â”‚
â”‚  - Results: .workflow/outputs/EPIC-ID/                        â”‚
â”‚  - Post-mortem: .workflow/post-mortem/EPIC-ID.md              â”‚
â”‚  - GitHub issues closed (optional)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Orchestrator Pattern

### Orchestrator vs Agent Roles

**Orchestrator (execute-workflow.md):**
- Coordinates workflow phases
- Deploys agents using Task tool
- Reads and parses results from agents
- Makes decisions based on results
- Handles errors and edge cases
- **DOES NOT:** Write code, modify files, or implement features

**Agents (implementation, build fixer, post-mortem):**
- Execute specific tasks
- Write code, modify files
- Run validation commands
- Write structured results (JSON or markdown)
- **DOES NOT:** Coordinate workflow, make cross-phase decisions

### Why This Pattern?

**Benefits:**
1. **Separation of concerns:** Orchestrator = coordination, agents = execution
2. **Testability:** Agents can be tested in isolation
3. **Observability:** Clear boundaries, structured outputs
4. **Composability:** Agents reusable across workflows
5. **Parallelism:** Orchestrator can deploy multiple agents simultaneously

**Trade-offs:**
- More complex than monolithic approach
- Requires structured communication (JSON results)
- Agents must be self-contained (all context provided upfront)

---

## Agent System

### Agent Composition

An agent is composed of:

```
Agent Instance = Agent Definition + Domain Briefing(s) + Epic Context
```

**1. Agent Definition** (`agent_definitions/implementation_agent_v1.md`)
- Phase-specific rules (MUST/MUST NOT)
- Output format specification
- Validation checklist
- Error recovery guidance

**2. Domain Briefing** (`agent_briefings/backend_implementation.md`)
- Domain-specific patterns (service layer, error handling)
- Project coding standards
- Common pitfalls and solutions
- Code examples

**3. Epic Context** (provided by orchestrator)
- `spec.md` - What to build
- `architecture.md` - Design decisions
- `file-tasks.md` - Exactly how to build it (prescriptive plan)

### Agent Types

#### Implementation Agent V1

**Purpose:** Execute prescriptive plans exactly as specified

**Responsibilities:**
- Read domain briefing, project architecture, epic context
- Follow `file-tasks.md` prescriptive plan exactly
- Create/modify files as specified
- Add error handling for all operations
- Run syntax checks (Python: `python -m py_compile`, TypeScript: `tsc --noEmit`)
- Write structured results JSON

**Output Format:**
```json
{
  "status": "success|partial|failed",
  "epic_id": "EPIC-XXX",
  "agent_type": "implementation-agent-v1",
  "execution_mode": "sequential|parallel",
  "worktree_path": "/path/to/worktree (if parallel)",
  "files_created": ["path/to/file1.py", "path/to/file2.py"],
  "files_modified": ["path/to/existing_file.py"],
  "issues_encountered": [
    {
      "description": "Type hint unclear for async function return",
      "file": "src/backend/service.py",
      "resolution": "Assumed -> Coroutine[None], please verify"
    }
  ],
  "clarifications_needed": [
    "Should EmailService.send() be async or sync?"
  ],
  "completion_timestamp": "2025-10-19T14:30:00Z"
}
```

**Key Rules:**
- MUST follow prescriptive plan exactly
- MUST add error handling
- MUST write results JSON before completing
- MUST NOT write tests (testing phase handles this)
- MUST NOT refactor unrelated code
- MUST NOT skip error handling

#### Build Fixer Agent V1

**Purpose:** Fix validation errors through auto-fixes and manual corrections

**Responsibilities:**
- Read validation error logs
- Apply auto-fixes (`ruff check --fix`, `ruff format`)
- Fix manual errors (type hints, imports)
- Re-run validation commands
- Write structured results JSON

**Capabilities:**
1. **Auto-fix linting:** `ruff check --fix .`
2. **Auto-format:** `ruff format .`
3. **Add type hints:** Parse mypy errors, add missing types
4. **Fix import order:** Auto-fixed by ruff
5. **Fix line length:** Auto-fixed by ruff format
6. **Document blockers:** Clear reporting of unfixable issues

**Output Format:**
```json
{
  "status": "passed|failed",
  "attempt_number": 1,
  "epic_id": "EPIC-XXX",
  "agent_type": "build-fixer-agent-v1",
  "validation_results": {
    "lint": {
      "status": "passed",
      "command": "ruff check .",
      "errors_found": 8,
      "errors_fixed": 8,
      "auto_fixed": 7,
      "manual_fixed": 1
    },
    "format": {
      "status": "passed",
      "command": "ruff format --check .",
      "errors_found": 5,
      "errors_fixed": 5
    },
    "typecheck": {
      "status": "passed",
      "command": "mypy src/",
      "errors_found": 3,
      "errors_fixed": 3
    }
  },
  "fixes_applied": [
    {
      "file": "src/api/handlers.py",
      "issue": "Missing return type hint",
      "fix": "Added -> Response"
    }
  ],
  "remaining_issues": [],
  "completion_timestamp": "2025-10-19T14:35:00Z"
}
```

#### Post-Mortem Agent V1

**Purpose:** Analyze workflow execution and generate actionable recommendations

**Responsibilities:**
- Review all workflow artifacts (JSON results, git changes)
- Answer 4 post-mortem questions:
  1. What worked well?
  2. What challenges occurred?
  3. How were challenges resolved?
  4. What should improve next time?
- Provide specific, actionable recommendations
- Write structured markdown report

**Analysis Scope:**

**Sequential Execution:**
- Implementation quality (code, patterns, architecture)
- Prescriptive plan clarity (was it followed exactly?)
- Validation effectiveness (did it catch real issues?)
- Briefing helpfulness (did examples apply?)

**Parallel Execution (Additional):**
- Worktree management (creation, isolation, cleanup)
- Domain separation quality (file overlap, boundaries)
- Parallel effectiveness (actual speedup vs expected)
- Merge smoothness (conflicts, order, timing)

**Output Format:**
```markdown
---
epic_id: EPIC-XXX
title: [Epic Title]
completed_at: 2025-10-19T14:40:00Z
execution_mode: sequential|parallel
parallel_agents: 0|2|3
---

# Post-Mortem: EPIC-XXX

## Summary
[1-2 sentences: High-level overview, key outcome, major achievements/issues]

## Execution Details
- Files created: 2
- Files modified: 3
- Execution mode: sequential
- Duration: ~15 minutes
- Validation attempts: 1
- Final status: Success

## What Worked Well
[3-5 specific items with examples, file names, patterns]

## Challenges Encountered
[2-4 items with description, impact, root cause, resolution, lesson]

## Recommendations
### Briefing Updates
[Specific files, specific additions]

### Process Improvements
[Workflow changes]

### Pattern Additions
[New reusable patterns]

## Metrics
- Validation pass rate: 100%
- Build/lint/type errors fixed: 3
- Architecture violations: 0

## Artifacts
- Implementation results: .workflow/outputs/EPIC-XXX/phase1_results.json
- Git commit: a3f2b1c
```

---

## Phase-by-Phase Deep Dive

### Phase 0: Preflight Checks

**Purpose:** Verify epic readiness before execution

**Steps:**

1. **Find Epic Directory**
   ```bash
   EPIC_DIR=$(find .tasks -name "${ARGUMENTS}-*" -type d | head -1)
   ```

2. **Verify Required Files**
   - âœ… `spec.md` exists
   - âœ… `architecture.md` exists
   - âœ… `implementation-details/file-tasks.md` exists

3. **Verify Git Working Directory**
   ```bash
   git status --porcelain  # Must be empty
   ```

4. **Parallel Detection**
   ```bash
   python3 ~/tier1_workflow_global/implementation/parallel_detection.py \
     "${EPIC_DIR}/implementation-details/file-tasks.md"
   ```

   **Detection Algorithm:**
   - Extract all file paths from `file-tasks.md`
   - Count total files
   - Classify files by domain (backend, frontend, database, tests, docs)
   - Count distinct domains
   - Calculate file overlap between domains
   - Apply thresholds:
     - `file_count >= 8` AND
     - `domain_count >= 2` AND
     - `file_overlap < 30%`
   - Output: `parallel_analysis.json`

5. **Check GitHub CLI Availability**
   ```bash
   command -v gh && gh auth status
   ```

6. **Display Epic Summary**
   - Epic ID, title, file count, execution mode

**Outputs:**
- `.workflow/outputs/${EPIC_ID}/parallel_analysis.json`
- `.workflow/outputs/${EPIC_ID}/github_available.txt`
- `EXECUTION_MODE` environment variable set

**Failure Modes:**
- Epic directory not found â†’ Error, suggest `/task-list`
- Missing files â†’ Error, suggest `/refine-epic`
- Git not clean â†’ Error, suggest commit or stash
- Parallel detection fails â†’ Fallback to sequential

---

### Phase 1A: Sequential Implementation

**Condition:** `EXECUTION_MODE == "sequential"`

**Purpose:** Deploy single agent to execute prescriptive plan

**Steps:**

1. **Read Epic Context**
   - `spec.md`
   - `architecture.md`
   - `file-tasks.md`

2. **Determine Domain**
   - Parse `file-tasks.md` to identify primary domain
   - Select appropriate domain briefing (backend, frontend, database, etc.)

3. **Compose Agent Prompt**
   ```markdown
   YOU ARE: Implementation Agent V1

   [Read agent_definitions/implementation_agent_v1.md]

   DOMAIN BRIEFING:
   [Read agent_briefings/backend_implementation.md]

   PROJECT ARCHITECTURE:
   [Read agent_briefings/project_architecture.md]

   EPIC SPECIFICATION:
   [Read spec.md]

   ARCHITECTURE:
   [Read architecture.md]

   PRESCRIPTIVE PLAN:
   [Read file-tasks.md]

   OUTPUT FILE:
   .workflow/outputs/${EPIC_ID}/phase1_results.json

   BEGIN IMPLEMENTATION.
   ```

4. **Deploy Agent**
   ```python
   Task(
       subagent_type="general-purpose",
       description=f"Sequential implementation for {EPIC_ID}",
       prompt=AGENT_PROMPT
   )
   ```

5. **Wait for Completion**
   - Agent writes `phase1_results.json` when complete

6. **Read Results**
   ```bash
   IMPL_STATUS=$(jq -r '.status' .workflow/outputs/${EPIC_ID}/phase1_results.json)
   FILES_CREATED=$(jq -r '.files_created | length' .workflow/outputs/${EPIC_ID}/phase1_results.json)
   ```

**Outputs:**
- `.workflow/outputs/${EPIC_ID}/phase1_results.json`

**Failure Modes:**
- Agent doesn't write results â†’ Timeout, manual intervention
- Status = "failed" â†’ Display issues, manual intervention
- Status = "partial" â†’ Display clarifications needed, decide whether to proceed

---

### Phase 1B: Parallel Implementation

**Condition:** `EXECUTION_MODE == "parallel"`

**Purpose:** Deploy multiple agents in isolated worktrees for parallel execution

**Steps:**

1. **Load Parallel Plan**
   ```bash
   PARALLEL_PLAN=$(cat .workflow/outputs/${EPIC_ID}/parallel_analysis.json)
   DOMAINS=$(echo "$PARALLEL_PLAN" | jq -r '.parallel_plan | keys[]')
   ```

2. **Create GitHub Epic Issue (Optional)**
   ```bash
   if [ "$GITHUB_AVAILABLE" -eq 1 ]; then
     gh issue create --title "${EPIC_TITLE}" --body "${EPIC_BODY}" --label "type:epic,execution:parallel"
   fi
   ```

3. **Create Worktrees**
   ```python
   # For each domain:
   from worktree_manager import create_worktree_for_agent

   metadata = create_worktree_for_agent(
       epic_id="EPIC-XXX",
       task_name="backend",
       base_branch="main"
   )

   # Returns:
   # - Worktree path: .worktrees/EPIC-XXX-backend-a3f2b1c4/
   # - Branch name: feature/EPIC-XXX/backend
   # - Metadata file: .worktrees/.metadata/EPIC-XXX-backend-a3f2b1c4.json
   ```

   **Worktree Structure:**
   ```
   .worktrees/
   â”œâ”€â”€ EPIC-XXX-backend-a3f2b1c4/          # Backend worktree (full repo copy)
   â”œâ”€â”€ EPIC-XXX-frontend-d5e6f7g8/         # Frontend worktree
   â”œâ”€â”€ EPIC-XXX-database-h9i0j1k2/         # Database worktree
   â””â”€â”€ .metadata/
       â”œâ”€â”€ EPIC-XXX-backend-a3f2b1c4.json  # Metadata (status, timestamps, branch)
       â”œâ”€â”€ EPIC-XXX-frontend-d5e6f7g8.json
       â””â”€â”€ EPIC-XXX-database-h9i0j1k2.json
   ```

4. **Create GitHub Sub-Issues (Optional)**
   ```bash
   for domain in $DOMAINS; do
     gh issue create --title "${EPIC_ID}: ${domain} Implementation" --label "type:task,domain:${domain},parent:${EPIC_ISSUE}"
   done
   ```

5. **Deploy Parallel Agents (SINGLE MESSAGE)**

   **CRITICAL:** All `Task()` calls must be in ONE message for parallel execution.

   ```python
   # Orchestrator sends single message with ALL agents:

   # Backend Agent
   Task(
       subagent_type="general-purpose",
       description=f"Backend implementation for {EPIC_ID}",
       prompt=f"""
       YOU ARE: Implementation Agent V1

       WORKTREE DIRECTORY: {WORKTREE_PATHS['backend']}

       CRITICAL: cd {WORKTREE_PATHS['backend']}

       [Agent definition + backend briefing + epic context]

       PRESCRIPTIVE PLAN (backend domain only):
       {PARALLEL_PLAN.backend.task_description}

       FILES (backend only):
       {PARALLEL_PLAN.backend.files[]}

       OUTPUT FILE:
       {WORKTREE_PATHS['backend']}/.workflow/outputs/{EPIC_ID}/backend_results.json
       """
   )

   # Frontend Agent
   Task(
       subagent_type="general-purpose",
       description=f"Frontend implementation for {EPIC_ID}",
       prompt=f"""
       [Similar to backend, with frontend worktree path and files]
       """
   )

   # Database Agent
   Task(
       subagent_type="general-purpose",
       description=f"Database implementation for {EPIC_ID}",
       prompt=f"""
       [Similar to backend, with database worktree path and files]
       """
   )
   ```

6. **Wait for Agent Completion**
   - Claude Code executes all Task() calls in parallel
   - Orchestrator waits for ALL agents to complete

7. **Collect Results from Worktrees**
   ```bash
   for domain in $DOMAINS; do
     WORKTREE_PATH="${WORKTREE_PATHS[$domain]}"
     RESULT_FILE="${WORKTREE_PATH}/.workflow/outputs/${EPIC_ID}/${domain}_results.json"

     # Parse results
     STATUS=$(jq -r '.status' "$RESULT_FILE")
     FILES_CREATED=$(jq -r '.files_created | length' "$RESULT_FILE")
     FILES_MODIFIED=$(jq -r '.files_modified | length' "$RESULT_FILE")

     # Copy results to main repo
     cp "$RESULT_FILE" .workflow/outputs/${EPIC_ID}/
   done
   ```

8. **Aggregate Results**
   ```json
   {
     "phase": "1B",
     "execution_mode": "parallel",
     "epic_id": "EPIC-XXX",
     "timestamp": "2025-10-19T14:30:00Z",
     "domains": ["backend", "frontend", "database"],
     "domain_results": {
       "backend": {
         "status": "success",
         "worktree_path": ".worktrees/EPIC-XXX-backend-a3f2b1c4/",
         "worktree_branch": "feature/EPIC-XXX/backend",
         "files_created": 4,
         "files_modified": 2
       }
     },
     "summary": {
       "total_domains": 3,
       "successful": 3,
       "partial": 0,
       "failed": 0,
       "overall_status": "success"
     }
   }
   ```

**Outputs:**
- `.workflow/outputs/${EPIC_ID}/phase1_parallel_results.json` (aggregate)
- `.workflow/outputs/${EPIC_ID}/backend_results.json`
- `.workflow/outputs/${EPIC_ID}/frontend_results.json`
- `.workflow/outputs/${EPIC_ID}/database_results.json`
- `.workflow/outputs/${EPIC_ID}/github_epic_issue.txt` (optional)
- `.workflow/outputs/${EPIC_ID}/github_sub_issues.json` (optional)

**Failure Modes:**
- Worktree creation fails â†’ Error, cleanup partial worktrees, exit
- Any agent fails â†’ Block merge (Phase 1C), manual intervention
- Results file missing â†’ Mark domain as failed, block merge

---

### Phase 1C: Sequential Merge

**Condition:** `EXECUTION_MODE == "parallel"` (runs after Phase 1B)

**Purpose:** Merge worktree branches back into main branch in dependency order

**Steps:**

1. **Verify All Agents Succeeded**
   ```bash
   for domain in $DOMAINS; do
     STATUS="${DOMAIN_STATUS[$domain]}"
     if [ "$STATUS" != "success" ]; then
       echo "âŒ Cannot merge: ${domain} implementation failed"
       exit 1
     fi
   done
   ```

2. **Determine Merge Order (Dependency-Based)**
   ```bash
   # Standard order: database â†’ backend â†’ frontend â†’ tests â†’ docs

   ORDERED_DOMAINS=()
   [ -n "$(echo $DOMAINS | grep database)" ] && ORDERED_DOMAINS+=("database")
   [ -n "$(echo $DOMAINS | grep backend)" ] && ORDERED_DOMAINS+=("backend")
   [ -n "$(echo $DOMAINS | grep frontend)" ] && ORDERED_DOMAINS+=("frontend")
   [ -n "$(echo $DOMAINS | grep tests)" ] && ORDERED_DOMAINS+=("tests")
   [ -n "$(echo $DOMAINS | grep docs)" ] && ORDERED_DOMAINS+=("docs")
   ```

   **Why This Order?**
   - **Database first:** Schema changes must exist before backend uses them
   - **Backend second:** API endpoints must exist before frontend calls them
   - **Frontend third:** UI components depend on backend APIs
   - **Tests fourth:** Tests validate all layers
   - **Docs last:** Documentation describes completed features

3. **Sequential Merge with Conflict Detection**
   ```bash
   cd "$(git rev-parse --show-toplevel)"  # Return to main repo

   for domain in "${ORDERED_DOMAINS[@]}"; do
     BRANCH_NAME=$(get_branch_from_worktree_metadata "$domain")

     # Merge (no-fast-forward preserves history)
     git merge --no-ff "${BRANCH_NAME}" -m "Merge ${domain} implementation for ${EPIC_ID}"

     # Check for conflicts
     if [ $? -ne 0 ]; then
       echo "âŒ Merge conflict detected in ${domain}"

       # Show conflicted files
       git diff --name-only --diff-filter=U

       # Abort this merge
       git merge --abort

       # Record conflict and exit
       MERGE_CONFLICTS+=("${domain}")
       MERGE_FAILED=1
     fi
   done
   ```

4. **Handle Merge Conflicts**

   If conflicts detected:
   ```bash
   # Write conflict state
   cat > .workflow/outputs/${EPIC_ID}/merge_conflicts.json << EOF
   {
     "status": "conflicts",
     "conflicted_domains": ["backend", "frontend"],
     "resolution_required": true,
     "next_steps": [
       "Manually merge conflicted branches",
       "Resolve conflicts in editor",
       "Stage changes: git add .",
       "Commit: git commit",
       "Run validation: npm run validate-all",
       "Resume workflow: /execute-workflow ${EPIC_ID} --resume"
     ],
     "conflict_timestamp": "2025-10-19T14:35:00Z"
   }
   EOF

   # Display manual resolution guidance
   echo "Manual resolution required:"
   echo "  git merge feature/EPIC-XXX/backend"
   echo "  # Resolve conflicts"
   echo "  git add ."
   echo "  git commit"

   exit 1
   ```

5. **Close GitHub Sub-Issues (Optional)**
   ```bash
   for domain in "${ORDERED_DOMAINS[@]}"; do
     SUB_ISSUE=$(get_sub_issue_number "$domain")
     gh issue close ${SUB_ISSUE} --comment "âœ… Merged successfully into main branch"
   done
   ```

6. **Cleanup Worktrees**
   ```python
   from worktree_manager import cleanup_worktree

   for domain in ORDERED_DOMAINS:
       cleanup_worktree(
           worktree_name=WORKTREE_NAME,
           delete_branch=True  # Delete merged branch
       )
   ```

   **Cleanup Actions:**
   - Remove worktree directory (`.worktrees/EPIC-XXX-backend-a3f2b1c4/`)
   - Delete feature branch (`feature/EPIC-XXX/backend`)
   - Archive metadata (`.worktrees/.metadata/archived/EPIC-XXX-backend-a3f2b1c4.json`)

7. **Create Merge Summary**
   ```json
   {
     "status": "success",
     "execution_mode": "parallel",
     "merge_order": ["database", "backend", "frontend"],
     "merged_domains": ["database", "backend", "frontend"],
     "conflicts": [],
     "worktrees_cleaned": true,
     "completion_timestamp": "2025-10-19T14:35:00Z"
   }
   ```

**Outputs:**
- `.workflow/outputs/${EPIC_ID}/merge_summary.json` (success)
- `.workflow/outputs/${EPIC_ID}/merge_conflicts.json` (if conflicts)

**Failure Modes:**
- Merge conflict â†’ Abort merge, write conflict state, exit with guidance
- Worktree cleanup fails â†’ Log warning, continue (non-critical)

---

### Phase 3: Validation with Retry Loop

**Purpose:** Validate implementation with automated checks and retry on failure

**Steps:**

1. **Initialize Retry Counter**
   ```bash
   VALIDATION_ATTEMPT=0
   MAX_VALIDATION_ATTEMPTS=3
   VALIDATION_PASSED=0
   ```

2. **Validation Retry Loop**
   ```bash
   while [ $VALIDATION_ATTEMPT -lt $MAX_VALIDATION_ATTEMPTS ] && [ $VALIDATION_PASSED -eq 0 ]; do
     VALIDATION_ATTEMPT=$((VALIDATION_ATTEMPT + 1))

     # Run validation
     if [ -f "package.json" ] && grep -q '"validate-all"' package.json; then
       npm run validate-all 2>&1 | tee .workflow/outputs/${EPIC_ID}/validation/attempt_${VALIDATION_ATTEMPT}.log
       VALIDATION_EXIT_CODE=${PIPESTATUS[0]}
     else
       # Fallback: Run individual commands
       ruff check . && ruff format --check . && mypy src/
       VALIDATION_EXIT_CODE=$?
     fi

     # Check result
     if [ $VALIDATION_EXIT_CODE -eq 0 ]; then
       VALIDATION_PASSED=1
       break
     fi

     # Deploy build fixer if attempts remaining
     if [ $VALIDATION_ATTEMPT -lt $MAX_VALIDATION_ATTEMPTS ]; then
       # Deploy build fixer agent
       Task(
           subagent_type="general-purpose",
           description="Fix validation errors",
           prompt="""
           YOU ARE: Build Fixer Agent V1

           VALIDATION LOG:
           [Read .workflow/outputs/${EPIC_ID}/validation/attempt_${VALIDATION_ATTEMPT}.log]

           FIX ALL ERRORS.

           OUTPUT: .workflow/outputs/${EPIC_ID}/fix_attempt_${VALIDATION_ATTEMPT}.json
           """
       )

       # Wait for fixer completion
       # Re-run validation on next loop iteration
     fi
   done
   ```

3. **Write Validation Result**
   ```json
   {
     "status": "passed|failed",
     "attempts": 2,
     "final_attempt_log": ".workflow/outputs/EPIC-XXX/validation/attempt_2.log",
     "max_attempts_reached": false,
     "timestamp": "2025-10-19T14:37:00Z"
   }
   ```

4. **Update GitHub Labels (Optional)**
   ```bash
   if [ $VALIDATION_PASSED -eq 1 ]; then
     gh issue edit ${EPIC_ISSUE} --add-label "status:validated"
   fi
   ```

**Validation Types:**

**Mandatory:**
- Build/compile (Python: `python -m py_compile`, TypeScript: `tsc --noEmit`)
- Linting (Python: `ruff check`, TypeScript: `eslint`)
- Formatting (Python: `ruff format --check`, TypeScript: `prettier --check`)
- Type checking (Python: `mypy`, TypeScript: built-in)

**Optional:**
- Architecture validation (`python3 tools/validate_architecture.py`)
- Contract validation (`python3 tools/validate_contracts.py`)
- Test coverage (Python: `pytest --cov`, TypeScript: `jest --coverage`)

**Outputs:**
- `.workflow/outputs/${EPIC_ID}/validation/result.json`
- `.workflow/outputs/${EPIC_ID}/validation/attempt_N.log`
- `.workflow/outputs/${EPIC_ID}/fix_attempt_N.json` (if fixer deployed)

**Failure Modes:**
- Max attempts reached â†’ Continue workflow with warning (non-blocking)
- Build fixer fails â†’ Continue retries until max attempts
- Validation scripts missing â†’ Log warning, skip optional validations

**Non-Blocking Philosophy:**
Validation failures are **non-blocking** - workflow continues to Phase 5. Why?
1. Early-stage projects may not have all validations configured
2. Projects may intentionally skip certain checks
3. False positives from validation tools
4. Manual intervention possible after commit

---

### Phase 5: Commit & Cleanup

**Purpose:** Create conventional commit and move epic to completed

**Steps:**

1. **Generate Commit Message**
   ```bash
   EPIC_TITLE=$(grep "^# " ${EPIC_DIR}/spec.md | head -1 | sed 's/^# //')

   TOTAL_FILES_CREATED=$(jq '.files_created | length' .workflow/outputs/${EPIC_ID}/phase1_results.json)
   TOTAL_FILES_MODIFIED=$(jq '.files_modified | length' .workflow/outputs/${EPIC_ID}/phase1_results.json)

   COMMIT_MESSAGE=$(cat << EOF
   feat(${EPIC_ID}): ${EPIC_TITLE}

   Implementation completed using ${EXECUTION_MODE} execution mode.

   Files created: ${TOTAL_FILES_CREATED}
   Files modified: ${TOTAL_FILES_MODIFIED}
   Execution mode: ${EXECUTION_MODE}

   Epic: ${EPIC_DIR}
   Results: .workflow/outputs/${EPIC_ID}/

   ðŸ¤– Generated with Claude Code
   https://claude.com/claude-code

   Co-Authored-By: Claude <noreply@anthropic.com>
   EOF
   )
   ```

2. **Create Commit**
   ```bash
   git add .
   git commit -m "${COMMIT_MESSAGE}"
   ```

3. **Move Epic to Completed**
   ```bash
   COMPLETED_DIR=".tasks/completed"
   mkdir -p "$COMPLETED_DIR"
   mv "$EPIC_DIR" "$COMPLETED_DIR/"
   ```

4. **Close GitHub Epic Issue (Optional)**
   ```bash
   gh issue close ${EPIC_ISSUE} --comment "âœ… Workflow complete - all phases passed"
   ```

**Outputs:**
- Git commit created
- Epic moved to `.tasks/completed/`
- GitHub issue closed (optional)

---

### Phase 6: Post-Mortem

**Purpose:** Analyze workflow execution and capture learnings

**Steps:**

1. **Deploy Post-Mortem Agent**
   ```python
   Task(
       subagent_type="general-purpose",
       description=f"Post-mortem analysis for {EPIC_ID}",
       prompt=f"""
       YOU ARE: Post-Mortem Agent V1

       EPIC: {EPIC_ID}
       EXECUTION MODE: {EXECUTION_MODE}

       ARTIFACTS:
       - Parallel analysis: .workflow/outputs/{EPIC_ID}/parallel_analysis.json
       - Implementation: .workflow/outputs/{EPIC_ID}/phase1_*_results.json
       - Merge summary: .workflow/outputs/{EPIC_ID}/merge_summary.json
       - Validation: .workflow/outputs/{EPIC_ID}/validation/result.json
       - Git changes: git diff HEAD~1

       EPIC CONTEXT:
       - Spec: {EPIC_DIR}/spec.md
       - Architecture: {EPIC_DIR}/architecture.md
       - Plan: {EPIC_DIR}/implementation-details/file-tasks.md

       ANSWER 4 QUESTIONS:
       1. What worked well?
       2. What challenges occurred?
       3. How were challenges resolved?
       4. What should improve next time?

       PROVIDE SPECIFIC RECOMMENDATIONS:
       - Briefing updates (exact files, exact additions)
       - Process improvements (workflow changes)
       - Pattern additions (new reusable patterns)

       OUTPUT: .workflow/post-mortem/{EPIC_ID}.md
       """
   )
   ```

2. **Read Post-Mortem Report**
   ```bash
   cat .workflow/post-mortem/${EPIC_ID}.md
   ```

3. **Display Key Recommendations**
   ```bash
   sed -n '/^## Recommendations/,/^## /p' .workflow/post-mortem/${EPIC_ID}.md
   ```

4. **Knowledge Capture Workflow**
   - Human reviews post-mortem report
   - Evaluates recommendations (generally applicable?)
   - Applies valuable suggestions to agent briefings
   - Commits briefing updates separately
   - Archives post-mortem for historical reference

**Outputs:**
- `.workflow/post-mortem/${EPIC_ID}.md`

---

## Parallel Execution System

### Parallel Detection Algorithm

**Input:** `file-tasks.md` (prescriptive plan)

**Process:**

1. **Extract File Paths**
   - Parse markdown headings and bullet points
   - Extract all file paths mentioned
   - Deduplicate

2. **Classify by Domain**
   ```python
   def classify_domain(file_path):
       if 'backend' in file_path or 'api' in file_path:
           return 'backend'
       elif 'frontend' in file_path or 'components' in file_path:
           return 'frontend'
       elif 'database' in file_path or 'migrations' in file_path:
           return 'database'
       elif 'test' in file_path:
           return 'tests'
       elif 'docs' in file_path or '.md' in file_path:
           return 'docs'
       else:
           return 'other'
   ```

3. **Calculate File Overlap**
   ```python
   def calculate_overlap(domains):
       total_overlaps = 0
       total_comparisons = 0

       for domain1, files1 in domains.items():
           for domain2, files2 in domains.items():
               if domain1 < domain2:
                   overlap = len(set(files1) & set(files2))
                   total_overlaps += overlap
                   total_comparisons += 1

       overlap_percentage = (total_overlaps / (len(all_files) * total_comparisons)) * 100
       return overlap_percentage
   ```

4. **Apply Thresholds**
   ```python
   viable = (
       file_count >= 8 and
       domain_count >= 2 and
       overlap_percentage < 30
   )
   ```

**Output:**
```json
{
  "viable": true,
  "reason": "8+ files, 2+ domains, <30% overlap",
  "file_count": 18,
  "domain_count": 3,
  "domains": {
    "backend": 6,
    "frontend": 6,
    "database": 3
  },
  "file_overlap_percentage": 5.2,
  "execution_mode": "parallel",
  "parallel_plan": {
    "backend": {
      "files": ["src/backend/service.py", ...],
      "task_description": "Implement backend API endpoints..."
    },
    "frontend": {
      "files": ["src/frontend/App.tsx", ...],
      "task_description": "Implement frontend components..."
    },
    "database": {
      "files": ["migrations/001_create_table.sql", ...],
      "task_description": "Create database schema..."
    }
  }
}
```

### Git Worktree Isolation

**Worktree Creation:**

```python
from worktree_manager import create_worktree_for_agent

metadata = create_worktree_for_agent(
    epic_id="EPIC-XXX",
    task_name="backend",
    base_branch="main"
)

# Creates:
# - Worktree directory: .worktrees/EPIC-XXX-backend-a3f2b1c4/
# - Feature branch: feature/EPIC-XXX/backend
# - Metadata file: .worktrees/.metadata/EPIC-XXX-backend-a3f2b1c4.json
```

**Worktree Benefits:**
- **Shared .git:** No duplicate objects, efficient storage
- **Isolated working directory:** No conflicts between agents
- **Native Git:** Built-in feature (Git 2.5+)
- **Automatic cleanup:** Removing worktree cleans up metadata

**Worktree Metadata:**
```json
{
  "name": "EPIC-XXX-backend-a3f2b1c4",
  "path": "/absolute/path/to/.worktrees/EPIC-XXX-backend-a3f2b1c4",
  "branch_name": "feature/EPIC-XXX/backend",
  "epic_id": "EPIC-XXX",
  "task_name": "backend",
  "status": "active",
  "created_at": "2025-10-19T14:25:00Z",
  "updated_at": "2025-10-19T14:30:00Z",
  "commit_sha": "a3f2b1c4d5e6f7g8h9i0j1k2l3m4n5o6p7q8r9s0"
}
```

### Domain Dependency Order

**Standard Merge Order:**
```
database â†’ backend â†’ frontend â†’ tests â†’ docs
```

**Rationale:**
- **Database:** Schema changes first (tables, indexes)
- **Backend:** API implementation depends on schema
- **Frontend:** UI depends on API endpoints
- **Tests:** Validate all layers
- **Docs:** Document completed features

**Custom Domains:**
Not currently supported (hardcoded order). Future enhancement.

### Parallel Speedup Calculation

**Expected Speedup:**
```
Sequential Time = sum(agent_times)
Parallel Time = max(agent_times) + merge_overhead

Speedup = Sequential Time / Parallel Time
```

**Example:**
```
Backend: 20 minutes
Frontend: 18 minutes
Database: 10 minutes

Sequential: 20 + 18 + 10 = 48 minutes
Parallel: max(20, 18, 10) + 2 (merge) = 22 minutes
Speedup: 48 / 22 = 2.2x
```

**Actual Performance:**
- **Merge overhead:** ~5-10 seconds per domain
- **Worktree creation/cleanup:** ~2-3 seconds per worktree
- **Total overhead:** ~30-45 seconds for 3 domains
- **Net speedup:** 2-4x depending on domain balance

---

## Validation System

### Validation Types

**Mandatory Validations:**
- Build/compile checks
- Linting (code quality)
- Formatting (code style)
- Type checking (type safety)

**Optional Validations:**
- Architecture validation (layer boundaries)
- Contract validation (API schemas)
- Test coverage (code coverage)

### Retry Loop Architecture

```
Attempt 1:
  Run validation
  â”œâ”€â–º Passed â†’ Exit loop
  â””â”€â–º Failed â†’ Deploy build fixer
      Run validation
      â”œâ”€â–º Passed â†’ Exit loop
      â””â”€â–º Failed â†’ Continue

Attempt 2:
  Run validation
  â”œâ”€â–º Passed â†’ Exit loop
  â””â”€â–º Failed â†’ Deploy build fixer
      Run validation
      â”œâ”€â–º Passed â†’ Exit loop
      â””â”€â–º Failed â†’ Continue

Attempt 3:
  Run validation
  â”œâ”€â–º Passed â†’ Exit loop
  â””â”€â–º Failed â†’ Max attempts reached
      Log warning, continue workflow (non-blocking)
```

### Build Fixer Agent Capabilities

**Auto-Fixes:**
- `ruff check --fix .` - Auto-fix linting errors
- `ruff format .` - Auto-format code
- Import order corrections
- Line length corrections

**Manual Fixes:**
- Add type hints (parse mypy errors)
- Fix import errors
- Resolve naming conflicts

**Limitations:**
- Cannot fix logic errors
- Cannot resolve complex type issues
- Cannot fix architectural violations

### Validation Scripts

**Template Location:** `~/tier1_workflow_global/implementation/validation_scripts/`

**Templates:**
1. `validate_architecture.py` - Layer boundary validation
2. `validate_contracts.py` - API schema validation
3. `README.md` - Customization guide

**Customization Workflow:**
```bash
# Copy templates
cp -r ~/tier1_workflow_global/implementation/validation_scripts/ ./tools/

# Customize for your project
nano tools/validate_architecture.py
# - Update layer definitions
# - Update import rules
# - Add project-specific checks

# Add to package.json
nano package.json
# "validate-all": "npm run lint && npm run typecheck && npm run validate-architecture"
```

---

## Post-Mortem System

### 4 Post-Mortem Questions

1. **What worked well?**
   - Clear prescriptive plans
   - Helpful agent briefings
   - Effective validation
   - Successful architectural patterns

2. **What challenges occurred?**
   - Validation failures
   - Unclear requirements
   - Missing type hints
   - Merge conflicts

3. **How were challenges resolved?**
   - Build fixer auto-fixes
   - Manual intervention
   - Architectural decisions
   - Workarounds

4. **What should improve next time?**
   - Briefing clarifications
   - Prescriptive plan improvements
   - Validation enhancements
   - Pattern documentation

### Recommendation Types

**Briefing Updates:**
```markdown
**Backend Briefing:** `.claude/agent_briefings/backend_implementation.md`

Add pattern: "When adding async API endpoints, always specify return types:
`async def get_email(id: int) -> Email:`"

Clarify: "Service methods should raise custom exceptions, not HTTPException"

Example: Add async error handling pattern:
\`\`\`python
@router.get("/emails/{id}")
async def get_email(id: int) -> Email:
    try:
        return await service.get_email(id)
    except EmailNotFoundError as e:
        raise HTTPException(status_code=404, detail=str(e))
\`\`\`
```

**Process Improvements:**
```markdown
**Validation Phase:**
- Add pre-validation type check before implementation starts
- Run type checker incrementally during implementation

**Prescriptive Plans:**
- Include type signature examples for async functions
- Specify error handling patterns explicitly
```

**Pattern Additions:**
```markdown
**Pattern: Async Error Handling in FastAPI**

\`\`\`python
@router.get("/resource/{id}")
async def get_resource(id: int) -> Resource:
    try:
        service = ResourceService(db)
        return await service.get_resource(id)
    except ResourceNotFoundError as e:
        raise HTTPException(status_code=404, detail=str(e))
\`\`\`

**Use Case:** API routes calling async service methods
```

### Knowledge Capture Workflow

1. **Agent Generates Report**
   - Analyzes workflow artifacts
   - Identifies patterns and issues
   - Writes structured markdown

2. **Human Reviews Report**
   - Reads full post-mortem
   - Evaluates recommendations
   - Decides what to apply

3. **Human Applies Recommendations**
   - Edits agent briefings
   - Updates workflow processes
   - Adds patterns to library
   - Commits changes separately

4. **Archive Post-Mortem**
   - Keep permanently in `.workflow/post-mortem/`
   - Historical reference
   - Trend analysis

---

## GitHub Integration

### Issue Structure

```
Epic Issue #42 (type:epic, status:in-progress, execution:parallel)
  â”œâ”€â–º Sub-Issue #43 (type:task, domain:backend, parent:42)
  â”œâ”€â–º Sub-Issue #44 (type:task, domain:frontend, parent:42)
  â””â”€â–º Sub-Issue #45 (type:task, domain:database, parent:42)
```

### Epic Issue Body

```markdown
## Epic: EPIC-XXX

**Execution Mode:** Parallel (3 domains, 18 files)

### Specification

[spec.md contents]

### Architecture

[architecture.md contents]

### Domains

- **backend**: 6 files
- **frontend**: 6 files
- **database**: 3 files

### Execution Plan

This epic will be implemented using parallel execution with git worktrees.

### Status

- [x] Phase 0: Preflight âœ…
- [ ] Phase 1B: Parallel Implementation
- [ ] Phase 1C: Sequential Merge
- [ ] Phase 2: Validation
- [ ] Phase 5: Commit & Cleanup

---
ðŸ¤– Generated with Claude Code
```

### Sub-Issue Body

```markdown
## EPIC-XXX: backend Implementation

**Parent Epic:** #42
**Domain:** backend
**Files:** 6

### Task Description

Implement backend API endpoints and service layer for email management.

### Files to Create/Modify

- `src/backend/services/email_service.py`
- `src/backend/api/email_routes.py`
- `src/backend/models/email.py`
- `src/backend/schemas/email.py`

### Execution Details

**Branch:** `feature/EPIC-XXX/backend`
**Worktree:** `.worktrees/EPIC-XXX-backend-a3f2b1c4/`

### Status

- [ ] Implementation
- [ ] Validation
- [ ] Merge

---
ðŸ¤– Generated with Claude Code
```

### GitHub Comments (Progress Updates)

**Phase 1B Complete:**
```markdown
## Phase 1B Complete: Parallel Implementation âœ…

All domain implementations have completed. Results:

- âœ… **backend**: Success (#43)
- âœ… **frontend**: Success (#44)
- âœ… **database**: Success (#45)

**Next Phase:** Sequential merge (Phase 1C)

---
Updated: 2025-10-19 14:30:00 UTC
```

**Phase 1C Complete:**
```markdown
## Phase 1C Complete: Sequential Merge âœ…

All domain branches merged successfully.

**Merge Order:**
1. database â†’ merged
2. backend â†’ merged
3. frontend â†’ merged

**Conflicts:** None detected
**Sub-issues:** All closed

**Next Phase:** Validation (Phase 2)

---
Updated: 2025-10-19 14:35:00 UTC
```

### Non-Blocking Philosophy

**GitHub operations NEVER block workflow:**
- Epic creation fails â†’ Log warning, continue without GitHub
- Sub-issue creation fails â†’ Log warning, continue
- Issue update fails â†’ Log warning, continue
- Network unavailable â†’ Skip GitHub operations

**Local `.tasks/` directory is source of truth.**

---

## File Structure

### Project Structure (After Installation)

```
your-project/
â”œâ”€â”€ .claude/
â”‚   â”œâ”€â”€ commands/
â”‚   â”‚   â”œâ”€â”€ execute-workflow.md         # Workflow orchestrator
â”‚   â”‚   â”œâ”€â”€ spec-epic.md                # Create epic
â”‚   â”‚   â”œâ”€â”€ refine-epic.md              # Generate plan
â”‚   â”‚   â”œâ”€â”€ task-list.md                # List epics
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ agent_briefings/
â”‚   â”‚   â”œâ”€â”€ backend_implementation.md   # Backend patterns
â”‚   â”‚   â”œâ”€â”€ frontend_implementation.md  # Frontend patterns
â”‚   â”‚   â”œâ”€â”€ database_implementation.md  # Database patterns
â”‚   â”‚   â””â”€â”€ project_architecture.md     # Project-wide architecture
â”‚   â””â”€â”€ settings.local.json             # Project settings
â”‚
â”œâ”€â”€ .tasks/
â”‚   â”œâ”€â”€ backlog/
â”‚   â”‚   â””â”€â”€ EPIC-001-add-feature/
â”‚   â”‚       â”œâ”€â”€ spec.md                 # Epic specification
â”‚   â”‚       â”œâ”€â”€ architecture.md         # Design decisions
â”‚   â”‚       â””â”€â”€ implementation-details/
â”‚   â”‚           â””â”€â”€ file-tasks.md       # Prescriptive plan
â”‚   â””â”€â”€ completed/
â”‚       â””â”€â”€ EPIC-XXX-old-epic/          # Completed epics
â”‚
â”œâ”€â”€ .workflow/
â”‚   â”œâ”€â”€ outputs/
â”‚   â”‚   â””â”€â”€ EPIC-001/
â”‚   â”‚       â”œâ”€â”€ parallel_analysis.json  # Parallel detection
â”‚   â”‚       â”œâ”€â”€ phase1_results.json     # Sequential results
â”‚   â”‚       â”œâ”€â”€ phase1_parallel_results.json  # Parallel aggregate
â”‚   â”‚       â”œâ”€â”€ backend_results.json    # Domain results
â”‚   â”‚       â”œâ”€â”€ merge_summary.json      # Merge results
â”‚   â”‚       â”œâ”€â”€ validation/
â”‚   â”‚       â”‚   â”œâ”€â”€ result.json         # Validation result
â”‚   â”‚       â”‚   â””â”€â”€ attempt_N.log       # Validation logs
â”‚   â”‚       â”œâ”€â”€ fix_attempt_N.json      # Build fixer results
â”‚   â”‚       â””â”€â”€ github_epic_issue.txt   # GitHub issue number
â”‚   â””â”€â”€ post-mortem/
â”‚       â””â”€â”€ EPIC-001.md                 # Post-mortem report
â”‚
â”œâ”€â”€ .worktrees/
â”‚   â”œâ”€â”€ EPIC-001-backend-a3f2b1c4/      # Backend worktree
â”‚   â”œâ”€â”€ EPIC-001-frontend-d5e6f7g8/     # Frontend worktree
â”‚   â””â”€â”€ .metadata/
â”‚       â”œâ”€â”€ EPIC-001-backend-a3f2b1c4.json  # Metadata
â”‚       â””â”€â”€ archived/                   # Cleaned worktrees
â”‚
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ validate_architecture.py       # Architecture validation
â”‚   â””â”€â”€ validate_contracts.py          # Contract validation
â”‚
â”œâ”€â”€ package.json                        # Validation scripts
â””â”€â”€ ...
```

### Tier 1 Workflow Global Structure

```
~/tier1_workflow_global/
â”œâ”€â”€ README.md                           # Project overview
â”œâ”€â”€ template/                           # Project template
â”‚   â”œâ”€â”€ .claude/
â”‚   â”‚   â”œâ”€â”€ commands/                   # Workflow commands
â”‚   â”‚   â””â”€â”€ agent_briefings/            # Briefing templates
â”‚   â”œâ”€â”€ .tasks/                         # Task structure
â”‚   â””â”€â”€ tools/                          # Validation templates
â”‚
â”œâ”€â”€ implementation/
â”‚   â”œâ”€â”€ agent_definitions/
â”‚   â”‚   â”œâ”€â”€ implementation_agent_v1.md  # Implementation agent
â”‚   â”‚   â”œâ”€â”€ build_fixer_agent_v1.md     # Build fixer agent
â”‚   â”‚   â””â”€â”€ post_mortem_agent_v1.md     # Post-mortem agent
â”‚   â”‚
â”‚   â”œâ”€â”€ agent_briefings/
â”‚   â”‚   â”œâ”€â”€ backend_implementation.md   # Backend patterns
â”‚   â”‚   â”œâ”€â”€ frontend_implementation.md  # Frontend patterns
â”‚   â”‚   â”œâ”€â”€ database_implementation.md  # Database patterns
â”‚   â”‚   â””â”€â”€ project_architecture.md     # Architecture template
â”‚   â”‚
â”‚   â”œâ”€â”€ worktree_manager/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ worktree_manager.py         # Worktree creation
â”‚   â”‚   â”œâ”€â”€ models.py                   # Data models
â”‚   â”‚   â”œâ”€â”€ cleanup.py                  # Cleanup utilities
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”‚
â”‚   â”œâ”€â”€ validation_scripts/
â”‚   â”‚   â”œâ”€â”€ validate_architecture.py    # Architecture validator
â”‚   â”‚   â”œâ”€â”€ validate_contracts.py       # Contract validator
â”‚   â”‚   â””â”€â”€ README.md                   # Customization guide
â”‚   â”‚
â”‚   â”œâ”€â”€ test_epics/                     # Test scenarios
â”‚   â”‚   â”œâ”€â”€ WEEK4-TEST-001-ValidationRetry/
â”‚   â”‚   â””â”€â”€ WEEK4-TEST-002-PostMortem/
â”‚   â”‚
â”‚   â”œâ”€â”€ parallel_detection.py           # Parallel detection
â”‚   â”œâ”€â”€ WORKFLOW_QUICK_START.md         # Quick start guide
â”‚   â”œâ”€â”€ WORKFLOW_USER_MANUAL.md         # User manual
â”‚   â”œâ”€â”€ WORKFLOW_COMPREHENSIVE_GUIDE.md # This file
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ docs/
    â””â”€â”€ assessment/                     # Planning documents
```

---

## Extension Points

### Custom Domain Definitions

**Current:** Hardcoded domains (backend, frontend, database, tests, docs)

**Future Extension:**
```json
{
  "custom_domains": {
    "mobile": {
      "patterns": ["src/mobile/**", "app/**"],
      "dependencies": ["backend"]
    },
    "infrastructure": {
      "patterns": ["terraform/**", "k8s/**"],
      "dependencies": []
    }
  }
}
```

### Custom Validation Scripts

**Extension Point:** `tools/` directory

**Example Custom Validator:**
```python
#!/usr/bin/env python3
"""
Custom domain-specific validation.

Validates business rules, domain invariants, etc.
"""

def validate_domain_rules():
    # Check business rules
    # Example: Ensure all API endpoints have rate limiting
    pass

if __name__ == "__main__":
    validate_domain_rules()
```

**Integration:**
```json
{
  "scripts": {
    "validate-domain": "python3 tools/validate_domain_rules.py",
    "validate-all": "npm run lint && npm run typecheck && npm run validate-domain"
  }
}
```

### Custom Agent Briefings

**Extension Point:** `.claude/agent_briefings/`

**Example Project-Specific Briefing:**
```markdown
# E-Commerce Domain Briefing

## Payment Processing Pattern

All payment operations must:
1. Use idempotency keys
2. Log to audit trail
3. Handle network retries (exponential backoff)
4. Validate against fraud detection

\`\`\`python
@router.post("/payments")
async def process_payment(payment: PaymentRequest, idempotency_key: str = Header()):
    # Idempotency check
    if existing := await get_payment_by_key(idempotency_key):
        return existing

    # Process payment
    try:
        result = await payment_service.process(payment)
        await audit_log.record(result)
        return result
    except NetworkError:
        # Retry with exponential backoff
        pass
\`\`\`
```

### Parallel Detection Customization

**Extension Point:** `parallel_detection.py` thresholds

**Current Thresholds:**
```python
THRESHOLDS = {
    'min_file_count': 8,
    'min_domain_count': 2,
    'max_file_overlap': 30  # percentage
}
```

**Custom Thresholds:**
```python
# Project-specific .claude/parallel_config.json
{
  "thresholds": {
    "min_file_count": 12,
    "min_domain_count": 3,
    "max_file_overlap": 20
  }
}
```

---

## Performance Characteristics

### Sequential Execution

**Typical Epic (12 files, 1 domain):**
- Phase 0 (Preflight): <1 second
- Phase 1A (Implementation): 15-30 minutes
- Phase 3 (Validation): 30 seconds - 2 minutes
- Phase 5 (Commit): <5 seconds
- Phase 6 (Post-Mortem): 2-5 minutes
- **Total:** 20-40 minutes

### Parallel Execution (3 Domains)

**Large Epic (18 files, 3 domains):**
- Phase 0 (Preflight): <1 second
- Phase 1B (Parallel Implementation): 20-25 minutes (vs 60-75 sequential)
- Phase 1C (Sequential Merge): 30-60 seconds
- Phase 3 (Validation): 30 seconds - 2 minutes
- Phase 5 (Commit): <5 seconds
- Phase 6 (Post-Mortem): 2-5 minutes
- **Total:** 25-35 minutes (vs 65-85 sequential)
- **Speedup:** 2-3x

### Validation Retry Loop

**Best Case (Pass on Attempt 1):**
- Validation: 30 seconds
- Total: 30 seconds

**Typical Case (Pass on Attempt 2):**
- Validation attempt 1: 30 seconds
- Build fixer: 2-5 minutes
- Validation attempt 2: 30 seconds
- Total: 3-6 minutes

**Worst Case (Fail After 3 Attempts):**
- Validation attempt 1: 30 seconds
- Build fixer: 2-5 minutes
- Validation attempt 2: 30 seconds
- Build fixer: 2-5 minutes
- Validation attempt 3: 30 seconds
- Total: 6-12 minutes
- Workflow continues (non-blocking)

### Worktree Overhead

**Per Worktree:**
- Creation: 2-3 seconds
- Cleanup: 2 seconds
- Branch deletion: <1 second

**3 Worktrees:**
- Total creation: 6-9 seconds
- Total cleanup: 6 seconds
- **Total overhead:** ~12-15 seconds

---

## Limitations and Trade-offs

### Current Limitations

**Parallel Execution:**
- Requires clean git working directory
- No existing worktrees for same epic
- Git 2.5+ required
- Heuristic-based domain detection (may misclassify)
- Hardcoded domain list (backend, frontend, database, tests, docs)

**Merge Conflict Handling:**
- Manual resolution required (no auto-merge)
- Workflow pauses until resolution
- Resume mechanism not yet implemented (Week 5)

**Validation:**
- No automatic validation in worktrees during execution
- Validation happens after merge (could be parallel in worktrees)
- Build fixer has limitations (cannot fix logic errors)

**GitHub Integration:**
- Requires `gh` CLI installed and authenticated
- No offline support for issue creation
- No automatic retry for failed GitHub operations

**Post-Mortem:**
- Single agent analysis (not multi-perspective)
- Manual knowledge capture (human must apply recommendations)
- No automated trend tracking

### Design Trade-offs

**Orchestrator Pattern:**
- âœ… Clear separation of concerns
- âœ… Testable, composable agents
- âŒ More complex than monolithic approach
- âŒ Requires structured communication

**Parallel Execution:**
- âœ… 2-4x speedup for large epics
- âœ… Worktree isolation prevents conflicts
- âŒ Overhead for small epics (not worth it)
- âŒ Requires clean git state

**Sequential Merge:**
- âœ… Conflict detection immediate and clear
- âœ… Dependency order respected
- âœ… Easy to debug
- âŒ Not truly parallel (but merge is fast)

**Non-Blocking Validation:**
- âœ… Workflow doesn't halt on validation failures
- âœ… Suitable for early-stage projects
- âœ… Human can review and fix
- âŒ May commit code with validation errors

**Manual Knowledge Capture:**
- âœ… Simple (no semantic infrastructure)
- âœ… Human judgment applied
- âœ… Transparent (understand all changes)
- âŒ Requires discipline to apply learnings
- âŒ No automated briefing updates

---

## Summary

The Tier 1 workflow provides:

**Automation:**
- Automated implementation from spec to commit
- Automatic parallel/sequential detection
- Automated validation with retry loop
- Automated knowledge capture

**Performance:**
- 2-4x speedup for large epics (parallel execution)
- Efficient git worktree isolation
- Minimal overhead (~30-45 seconds for 3 domains)

**Quality:**
- Prescriptive plans ensure consistency
- Agent briefings capture project patterns
- Validation ensures code quality
- Post-mortem enables continuous improvement

**Flexibility:**
- Sequential or parallel execution (automatic)
- Customizable validation scripts
- Customizable agent briefings
- Optional GitHub integration

**Week 4 Status:** COMPLETE (67% of roadmap)

**Next Steps:**
- Week 5: Documentation freshness, enhanced GitHub sync, workflow resume
- Week 6: Installation script, final testing, v1.0 release

---

**Generated:** 2025-10-19
**Version:** 1.0
**Author:** Claude Code (Tier 1 Workflow Implementation)
